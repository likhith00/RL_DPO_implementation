{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["! pip install torch==2.0.1 transformers peft accelerate trl bitsandbytes optimum auto-gptq"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -U datasets"]},{"cell_type":"markdown","metadata":{},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:07:43.922995Z","iopub.status.busy":"2024-02-21T04:07:43.922713Z","iopub.status.idle":"2024-02-21T04:07:51.109897Z","shell.execute_reply":"2024-02-21T04:07:51.109046Z","shell.execute_reply.started":"2024-02-21T04:07:43.922971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-21 04:07:48.264220: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-21 04:07:48.264276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-21 04:07:48.265915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import torch\n","from datasets import Dataset, load_dataset\n","from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from transformers import AutoTokenizer, TrainingArguments, AutoModelForCausalLM, GPTQConfig\n","from trl import DPOTrainer"]},{"cell_type":"markdown","metadata":{},"source":["### Login to Huggingface"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:08:08.464827Z","iopub.status.busy":"2024-02-21T04:08:08.463941Z","iopub.status.idle":"2024-02-21T04:08:08.490557Z","shell.execute_reply":"2024-02-21T04:08:08.489534Z","shell.execute_reply.started":"2024-02-21T04:08:08.464792Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"292de1a15a4043cfad69557da7c8aa87","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"markdown","metadata":{},"source":["### Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:08:19.377789Z","iopub.status.busy":"2024-02-21T04:08:19.377101Z","iopub.status.idle":"2024-02-21T04:08:49.258208Z","shell.execute_reply":"2024-02-21T04:08:49.257274Z","shell.execute_reply.started":"2024-02-21T04:08:19.377752Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n","You can remove this warning by passing 'token=<use_auth_token>' instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b526ee3e3fc4c4f9ff111843c3fcb02","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"765e00eab20d4258950df4be686681ce","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/226M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e60c290cc36b4fe39a5ed0929382bfeb","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/226M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea181aaee0914215bbcac16d529ec387","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbfd20fa65014f11a4a38af328dd5b11","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e37d3abfacfb439798bf0b5469f9cfd0","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/184M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6585eafc374146d7bae15f188be4cb13","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"905749f4f2be47f39c7c149b9b2423dc","version_major":2,"version_minor":0},"text/plain":["Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63675432f07c412c9f59ae4fc8954e02","version_major":2,"version_minor":0},"text/plain":["Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4be54dc75ba47aba5d352615e83c911","version_major":2,"version_minor":0},"text/plain":["Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8795cf3d577042e292dd29828b242fa6","version_major":2,"version_minor":0},"text/plain":["Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f3449dafb5140d29c5337d4d73e5785","version_major":2,"version_minor":0},"text/plain":["Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21f717f7ce4b48ea951b59a46d0205bf","version_major":2,"version_minor":0},"text/plain":["Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\n","        \"HuggingFaceH4/ultrafeedback_binarized\",\n","        split = \"test_prefs\",\n","        use_auth_token=True\n",")\n","\n","original_columns = dataset.column_names"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:08:55.453660Z","iopub.status.busy":"2024-02-21T04:08:55.453251Z","iopub.status.idle":"2024-02-21T04:08:55.459507Z","shell.execute_reply":"2024-02-21T04:08:55.458267Z","shell.execute_reply.started":"2024-02-21T04:08:55.453628Z"},"trusted":true},"outputs":[],"source":["def return_prompt_and_responses(samples):\n","    return {\n","        \"prompt\": [prompt for prompt in samples[\"prompt\"]],\n","        \"chosen\": samples[\"chosen\"],\n","        \"rejected\": samples[\"rejected\"],\n","    }"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:08:56.916223Z","iopub.status.busy":"2024-02-21T04:08:56.915797Z","iopub.status.idle":"2024-02-21T04:08:57.094768Z","shell.execute_reply":"2024-02-21T04:08:57.093835Z","shell.execute_reply.started":"2024-02-21T04:08:56.916180Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1eea31b84284aa3a36f9a1eea4c99c3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = dataset.map(\n","        return_prompt_and_responses,\n","        batched=True,\n","        remove_columns=original_columns,\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:03.665061Z","iopub.status.busy":"2024-02-21T04:09:03.664185Z","iopub.status.idle":"2024-02-21T04:09:03.671232Z","shell.execute_reply":"2024-02-21T04:09:03.670371Z","shell.execute_reply.started":"2024-02-21T04:09:03.665027Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['prompt', 'chosen', 'rejected'],\n","    num_rows: 2000\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:05.209368Z","iopub.status.busy":"2024-02-21T04:09:05.208700Z","iopub.status.idle":"2024-02-21T04:09:06.629205Z","shell.execute_reply":"2024-02-21T04:09:06.628228Z","shell.execute_reply.started":"2024-02-21T04:09:05.209334Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>chosen</th>\n","      <th>rejected</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In this task, you are given a second sentence....</td>\n","      <td>[{'content': 'In this task, you are given a se...</td>\n","      <td>[{'content': 'In this task, you are given a se...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The floor of a rectangular room is 19 m long a...</td>\n","      <td>[{'content': 'The floor of a rectangular room ...</td>\n","      <td>[{'content': 'The floor of a rectangular room ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Definition: In this task, you are given an abs...</td>\n","      <td>[{'content': 'Definition: In this task, you ar...</td>\n","      <td>[{'content': 'Definition: In this task, you ar...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Evaluate the extent to which web usability is ...</td>\n","      <td>[{'content': 'Evaluate the extent to which web...</td>\n","      <td>[{'content': 'Evaluate the extent to which web...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A text is given in Bengali. Translate it from ...</td>\n","      <td>[{'content': 'A text is given in Bengali. Tran...</td>\n","      <td>[{'content': 'A text is given in Bengali. Tran...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>can you give me an overview of my mri medical ...</td>\n","      <td>[{'content': 'can you give me an overview of m...</td>\n","      <td>[{'content': 'can you give me an overview of m...</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>QUESTION: Can we conclude from \"Two men hold b...</td>\n","      <td>[{'content': 'QUESTION: Can we conclude from \"...</td>\n","      <td>[{'content': 'QUESTION: Can we conclude from \"...</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>Construct lyrics in the style of The Proclaime...</td>\n","      <td>[{'content': 'Construct lyrics in the style of...</td>\n","      <td>[{'content': 'Construct lyrics in the style of...</td>\n","    </tr>\n","    <tr>\n","      <th>1998</th>\n","      <td>Detailed Instructions: In this task, you will ...</td>\n","      <td>[{'content': 'Detailed Instructions: In this t...</td>\n","      <td>[{'content': 'Detailed Instructions: In this t...</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>You will be given a definition of a task first...</td>\n","      <td>[{'content': 'You will be given a definition o...</td>\n","      <td>[{'content': 'You will be given a definition o...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                                                 prompt  \\\n","0     In this task, you are given a second sentence....   \n","1     The floor of a rectangular room is 19 m long a...   \n","2     Definition: In this task, you are given an abs...   \n","3     Evaluate the extent to which web usability is ...   \n","4     A text is given in Bengali. Translate it from ...   \n","...                                                 ...   \n","1995  can you give me an overview of my mri medical ...   \n","1996  QUESTION: Can we conclude from \"Two men hold b...   \n","1997  Construct lyrics in the style of The Proclaime...   \n","1998  Detailed Instructions: In this task, you will ...   \n","1999  You will be given a definition of a task first...   \n","\n","                                                 chosen  \\\n","0     [{'content': 'In this task, you are given a se...   \n","1     [{'content': 'The floor of a rectangular room ...   \n","2     [{'content': 'Definition: In this task, you ar...   \n","3     [{'content': 'Evaluate the extent to which web...   \n","4     [{'content': 'A text is given in Bengali. Tran...   \n","...                                                 ...   \n","1995  [{'content': 'can you give me an overview of m...   \n","1996  [{'content': 'QUESTION: Can we conclude from \"...   \n","1997  [{'content': 'Construct lyrics in the style of...   \n","1998  [{'content': 'Detailed Instructions: In this t...   \n","1999  [{'content': 'You will be given a definition o...   \n","\n","                                               rejected  \n","0     [{'content': 'In this task, you are given a se...  \n","1     [{'content': 'The floor of a rectangular room ...  \n","2     [{'content': 'Definition: In this task, you ar...  \n","3     [{'content': 'Evaluate the extent to which web...  \n","4     [{'content': 'A text is given in Bengali. Tran...  \n","...                                                 ...  \n","1995  [{'content': 'can you give me an overview of m...  \n","1996  [{'content': 'QUESTION: Can we conclude from \"...  \n","1997  [{'content': 'Construct lyrics in the style of...  \n","1998  [{'content': 'Detailed Instructions: In this t...  \n","1999  [{'content': 'You will be given a definition o...  \n","\n","[2000 rows x 3 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_df = train_dataset.to_pandas()\n","train_df"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:13.195160Z","iopub.status.busy":"2024-02-21T04:09:13.194384Z","iopub.status.idle":"2024-02-21T04:09:13.205409Z","shell.execute_reply":"2024-02-21T04:09:13.204412Z","shell.execute_reply.started":"2024-02-21T04:09:13.195129Z"},"trusted":true},"outputs":[],"source":["train_df[\"chosen\"] = train_df[\"chosen\"].apply(lambda x: x[1][\"content\"])\n","train_df[\"rejected\"] = train_df[\"rejected\"].apply(lambda x: x[1][\"content\"])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:22.359805Z","iopub.status.busy":"2024-02-21T04:09:22.359411Z","iopub.status.idle":"2024-02-21T04:09:22.367557Z","shell.execute_reply":"2024-02-21T04:09:22.366379Z","shell.execute_reply.started":"2024-02-21T04:09:22.359775Z"},"trusted":true},"outputs":[],"source":["train_df = train_df.dropna()\n","val_df = train_df.sample(10)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:25.134340Z","iopub.status.busy":"2024-02-21T04:09:25.133952Z","iopub.status.idle":"2024-02-21T04:09:25.198826Z","shell.execute_reply":"2024-02-21T04:09:25.197894Z","shell.execute_reply.started":"2024-02-21T04:09:25.134311Z"},"trusted":true},"outputs":[],"source":["train_data = Dataset.from_pandas(train_df)\n","val_data = Dataset.from_pandas(val_df)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:27.655711Z","iopub.status.busy":"2024-02-21T04:09:27.655324Z","iopub.status.idle":"2024-02-21T04:09:27.662053Z","shell.execute_reply":"2024-02-21T04:09:27.661061Z","shell.execute_reply.started":"2024-02-21T04:09:27.655675Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['prompt', 'chosen', 'rejected'],\n","    num_rows: 2000\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["### Load Tokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:31.645434Z","iopub.status.busy":"2024-02-21T04:09:31.644745Z","iopub.status.idle":"2024-02-21T04:09:34.144955Z","shell.execute_reply":"2024-02-21T04:09:34.144016Z","shell.execute_reply.started":"2024-02-21T04:09:31.645403Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d79c1a76163041f384583f373157d964","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d58ec67ed1d4617a0027c20ec1e87ef","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f6a64db9c9a4d529e19f18333f8e329","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a060d87a7cfa47c3a519a78d27460710","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/OpenHermes-2-Mistral-7B-GPTQ\")\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_toke"]},{"cell_type":"markdown","metadata":{},"source":["### Load Model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:34.147195Z","iopub.status.busy":"2024-02-21T04:09:34.146775Z","iopub.status.idle":"2024-02-21T04:09:55.969526Z","shell.execute_reply":"2024-02-21T04:09:55.968701Z","shell.execute_reply.started":"2024-02-21T04:09:34.147149Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7543b0c59224603a9eeecb65d6145bf","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"869271b86cac40d18fb36b4896dd7e9b","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d296b9e07d4446ad899f6f39a6046c74","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n","You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"]}],"source":["model = AutoModelForCausalLM.from_pretrained(\"TheBloke/OpenHermes-2-Mistral-7B-GPTQ\", torch_dtype=torch.float16, low_cpu_mem_usage=True, quantization_config=GPTQConfig(bits=4, disable_exllama=True))\n","\n","model_ref = AutoModelForCausalLM.from_pretrained(\"TheBloke/OpenHermes-2-Mistral-7B-GPTQ\", torch_dtype=torch.float16, low_cpu_mem_usage=True, quantization_config=GPTQConfig(bits=4, disable_exllama=True))"]},{"cell_type":"markdown","metadata":{},"source":["### Define Peft Config"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:09:55.972414Z","iopub.status.busy":"2024-02-21T04:09:55.971956Z","iopub.status.idle":"2024-02-21T04:09:55.977238Z","shell.execute_reply":"2024-02-21T04:09:55.976266Z","shell.execute_reply.started":"2024-02-21T04:09:55.972379Z"},"trusted":true},"outputs":[],"source":["peft_config = LoraConfig(\n","        r=8,\n","        lora_alpha=8,\n","        lora_dropout=0.1,\n","        target_modules=[\"q_proj\", \"v_proj\"],\n","        bias=\"none\",\n","        task_type=\"CAUSAL_LM\",\n","    )\n","peft_config.inference_mode = False"]},{"cell_type":"markdown","metadata":{},"source":["### Load peft config to model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:10:02.113151Z","iopub.status.busy":"2024-02-21T04:10:02.112785Z","iopub.status.idle":"2024-02-21T04:10:02.358572Z","shell.execute_reply":"2024-02-21T04:10:02.357743Z","shell.execute_reply.started":"2024-02-21T04:10:02.113127Z"},"trusted":true},"outputs":[],"source":["model = prepare_model_for_kbit_training(model)\n","model.config.use_cache=False\n","model.gradient_checkpointing_enable()\n","model.config.pretraining_tp=1\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"markdown","metadata":{},"source":["### Define Training Arguments"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:10:14.227624Z","iopub.status.busy":"2024-02-21T04:10:14.226558Z","iopub.status.idle":"2024-02-21T04:10:14.237875Z","shell.execute_reply":"2024-02-21T04:10:14.236590Z","shell.execute_reply.started":"2024-02-21T04:10:14.227578Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","        per_device_train_batch_size=1,\n","        max_steps=50,\n","        remove_unused_columns=False,\n","        gradient_accumulation_steps=1,\n","        learning_rate=2e-4,\n","        evaluation_strategy=\"steps\",\n","        logging_first_step=True,\n","        logging_steps=10,\n","        output_dir=\"openhermes-mistral-dpo-gptq\",\n","        optim=\"paged_adamw_32bit\",\n","        warmup_steps=2,\n","        fp16=True,\n","        push_to_hub=True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### Define DPO trainer"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:10:15.265131Z","iopub.status.busy":"2024-02-21T04:10:15.264244Z","iopub.status.idle":"2024-02-21T04:10:50.463372Z","shell.execute_reply":"2024-02-21T04:10:50.462507Z","shell.execute_reply.started":"2024-02-21T04:10:15.265090Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e04b9dc56b9427aacc20e94da5408c6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"492241d433a5424db3c7a3311ddff25c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dpo_trainer = DPOTrainer(\n","        model,\n","        model_ref,\n","        args=training_args,\n","        beta=0.1,\n","        train_dataset=train_data,\n","        eval_dataset=val_data,\n","        tokenizer=tokenizer,\n","        max_length=512,\n","        max_target_length=256,\n","        max_prompt_length=256\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### Start Training"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:10:50.465162Z","iopub.status.busy":"2024-02-21T04:10:50.464865Z","iopub.status.idle":"2024-02-21T04:22:31.647566Z","shell.execute_reply":"2024-02-21T04:22:31.646447Z","shell.execute_reply.started":"2024-02-21T04:10:50.465138Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.16.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.2"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240221_041110-3yxq197b</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/likhith25/huggingface/runs/3yxq197b' target=\"_blank\">floating-pig-14</a></strong> to <a href='https://wandb.ai/likhith25/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/likhith25/huggingface' target=\"_blank\">https://wandb.ai/likhith25/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/likhith25/huggingface/runs/3yxq197b' target=\"_blank\">https://wandb.ai/likhith25/huggingface/runs/3yxq197b</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [50/50 10:42, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rewards/chosen</th>\n","      <th>Rewards/rejected</th>\n","      <th>Rewards/accuracies</th>\n","      <th>Rewards/margins</th>\n","      <th>Logps/rejected</th>\n","      <th>Logps/chosen</th>\n","      <th>Logits/rejected</th>\n","      <th>Logits/chosen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.683900</td>\n","      <td>0.641808</td>\n","      <td>0.194121</td>\n","      <td>0.044370</td>\n","      <td>0.562500</td>\n","      <td>0.149751</td>\n","      <td>-447.611816</td>\n","      <td>-594.149841</td>\n","      <td>-1.846663</td>\n","      <td>-1.739873</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.703800</td>\n","      <td>0.628574</td>\n","      <td>0.242755</td>\n","      <td>0.026516</td>\n","      <td>0.562500</td>\n","      <td>0.216240</td>\n","      <td>-447.790375</td>\n","      <td>-593.663513</td>\n","      <td>-1.846848</td>\n","      <td>-1.750949</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.638800</td>\n","      <td>0.621755</td>\n","      <td>0.229426</td>\n","      <td>-0.044639</td>\n","      <td>0.625000</td>\n","      <td>0.274066</td>\n","      <td>-448.501923</td>\n","      <td>-593.796814</td>\n","      <td>-1.840106</td>\n","      <td>-1.751867</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.648000</td>\n","      <td>0.621798</td>\n","      <td>0.128361</td>\n","      <td>-0.129863</td>\n","      <td>0.625000</td>\n","      <td>0.258224</td>\n","      <td>-449.354156</td>\n","      <td>-594.807495</td>\n","      <td>-1.833233</td>\n","      <td>-1.748695</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.673000</td>\n","      <td>0.628179</td>\n","      <td>0.064839</td>\n","      <td>-0.168207</td>\n","      <td>0.562500</td>\n","      <td>0.233046</td>\n","      <td>-449.737579</td>\n","      <td>-595.442688</td>\n","      <td>-1.827502</td>\n","      <td>-1.746451</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=50, training_loss=0.6696784782409668, metrics={'train_runtime': 700.8183, 'train_samples_per_second': 0.071, 'train_steps_per_second': 0.071, 'total_flos': 0.0, 'train_loss': 0.6696784782409668, 'epoch': 0.03})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["dpo_trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["### Save model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:22:43.247920Z","iopub.status.busy":"2024-02-21T04:22:43.247190Z","iopub.status.idle":"2024-02-21T04:22:46.922449Z","shell.execute_reply":"2024-02-21T04:22:46.921425Z","shell.execute_reply.started":"2024-02-21T04:22:43.247885Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6078d19490c4f988d4d691787d0dd75","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c2067a0a71140a1a7a97c38b39e834a","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09b518ee37584c95bdb4159f4f40de34","version_major":2,"version_minor":0},"text/plain":["events.out.tfevents.1708488650.9c270e1257ac.206.0:   0%|          | 0.00/12.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f6bc0cb8b104a4e9dd16e86c69ef77d","version_major":2,"version_minor":0},"text/plain":["Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d912a7deba4846548c3f5f99e2781fdf","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dpo_trainer.save_model(\"./mistral_DPO_model\")"]},{"cell_type":"markdown","metadata":{},"source":["### Push model to Hub"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:28:33.037052Z","iopub.status.busy":"2024-02-21T04:28:33.036223Z","iopub.status.idle":"2024-02-21T04:28:34.891626Z","shell.execute_reply":"2024-02-21T04:28:34.890375Z","shell.execute_reply.started":"2024-02-21T04:28:33.037017Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/likhith231/openhermes-mistral-dpo-gptq/commit/4323e68bbf2b75cbaad33560673000d61295205d', commit_message='openhermes-mistral-dpo-gptq', commit_description='', oid='4323e68bbf2b75cbaad33560673000d61295205d', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["dpo_trainer.push_to_hub(\"openhermes-mistral-dpo-gptq\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:30:10.533933Z","iopub.status.busy":"2024-02-21T04:30:10.533190Z","iopub.status.idle":"2024-02-21T04:30:20.619691Z","shell.execute_reply":"2024-02-21T04:30:20.618624Z","shell.execute_reply.started":"2024-02-21T04:30:10.533897Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1e1ac313e80429ca160db6543e802c8","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7775d626680643b799d9583cd4c1b332","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66c329d719ca447ea0bfb119a30b40cf","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b68d66583d0464ebc0bf3c3bf880b87","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21acc484949147c0ba2cc1dff684df33","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b01868b1e774159981edfe8437ef849","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d91042a6bf6e4b74bfad725f5dc2e876","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79cfb1e301d4411092e40a44f46bbd35","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4903709c1db48c39ae799c7bf75315e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaab8cd0d8554817b0d4bfc732b557c9","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bed38a3021074bd19d26368713f662d8","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"441a3ba0101642bfb8f071d309ee37ea","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from peft import AutoPeftModelForCausalLM\n","from transformers import GenerationConfig\n","from transformers import AutoTokenizer\n","import torch\n","tokenizer = AutoTokenizer.from_pretrained(\"likhith231/openhermes-mistral-dpo-gptq\")\n","\n","inputs = tokenizer(\"\"\"I have dropped my phone in water. Now it is not working what should I do now?\"\"\", return_tensors=\"pt\").to(\"cuda\")\n","\n","model = AutoPeftModelForCausalLM.from_pretrained(\n","    \"likhith231/openhermes-mistral-dpo-gptq\",\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"cuda\")\n","\n","generation_config = GenerationConfig(\n","    do_sample=True,\n","    top_k=1,\n","    temperature=0.1,\n","    max_new_tokens=256,\n","    pad_token_id=tokenizer.eos_token_id\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T04:30:20.621540Z","iopub.status.busy":"2024-02-21T04:30:20.621241Z","iopub.status.idle":"2024-02-21T04:33:23.953603Z","shell.execute_reply":"2024-02-21T04:33:23.952526Z","shell.execute_reply.started":"2024-02-21T04:30:20.621514Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["I have dropped my phone in water. Now it is not working what should I do now?\n","\n","If you have dropped your phone in water, the first thing you should do is to turn it off immediately. If it is still on, turn it off. Then remove the battery if possible. If the battery is not removable, then leave the phone off.\n","\n","Next, you should try to dry the phone as much as possible. You can use a hair dryer or a fan to dry the phone. You can also use uncooked rice or silica gel packets to absorb the moisture.\n","\n","After the phone has dried, you can try to turn it on. If it does not turn on, you can try to charge it. If it still does not turn on, then you may need to take it to a professional for repair.\n","\n","If you have dropped your phone in water and it is not working, you should try to dry it as soon as possible. If it still does not work after drying, you may need to take it to a professional for repair.\n","183.3249475955963\n"]}],"source":["import time\n","st_time = time.time()\n","outputs = model.generate(**inputs, generation_config=generation_config)\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","print(time.time()-st_time)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
